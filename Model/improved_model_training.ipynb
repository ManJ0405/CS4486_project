{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "258d7363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253e6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "with open('../Data/processed_train_data.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('../Data/processed_test_data.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827f594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24499, 84, 84, 3)\n",
      "(24499,)\n",
      "{'AK': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'SCC': 6, 'VASC': 7}\n",
      "(800, 84, 84, 3)\n",
      "(800,)\n",
      "{'AK': 0, 'BCC': 1, 'BKL': 2, 'DF': 3, 'MEL': 4, 'NV': 5, 'SCC': 6, 'VASC': 7}\n",
      "[[[237 144 165]\n",
      "  [232 140 161]\n",
      "  [228 140 162]\n",
      "  ...\n",
      "  [232 139 157]\n",
      "  [236 148 164]\n",
      "  [245 161 176]]\n",
      "\n",
      " [[236 143 164]\n",
      "  [232 140 161]\n",
      "  [227 139 161]\n",
      "  ...\n",
      "  [232 139 157]\n",
      "  [241 150 167]\n",
      "  [250 166 181]]\n",
      "\n",
      " [[238 145 166]\n",
      "  [237 145 166]\n",
      "  [233 145 167]\n",
      "  ...\n",
      "  [237 143 161]\n",
      "  [247 156 173]\n",
      "  [255 168 184]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[227 137 147]\n",
      "  [231 138 149]\n",
      "  [233 132 146]\n",
      "  ...\n",
      "  [236 134 130]\n",
      "  [234 132 127]\n",
      "  [231 130 122]]\n",
      "\n",
      " [[227 137 147]\n",
      "  [230 137 148]\n",
      "  [232 131 145]\n",
      "  ...\n",
      "  [237 135 131]\n",
      "  [234 132 127]\n",
      "  [232 131 123]]\n",
      "\n",
      " [[229 137 148]\n",
      "  [233 137 149]\n",
      "  [234 132 146]\n",
      "  ...\n",
      "  [239 140 135]\n",
      "  [237 138 132]\n",
      "  [237 136 128]]]\n",
      "0\n",
      "[[[108  89  82]\n",
      "  [116  97  90]\n",
      "  [126 106  99]\n",
      "  ...\n",
      "  [209 185 185]\n",
      "  [205 181 181]\n",
      "  [202 178 178]]\n",
      "\n",
      " [[117  98  91]\n",
      "  [123 104  97]\n",
      "  [130 110 103]\n",
      "  ...\n",
      "  [206 182 182]\n",
      "  [204 180 180]\n",
      "  [204 180 180]]\n",
      "\n",
      " [[123 104  97]\n",
      "  [127 107 100]\n",
      "  [133 113 106]\n",
      "  ...\n",
      "  [204 178 177]\n",
      "  [204 178 177]\n",
      "  [205 179 178]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[111  77  75]\n",
      "  [118  84  82]\n",
      "  [125  90  88]\n",
      "  ...\n",
      "  [198 165 176]\n",
      "  [199 166 177]\n",
      "  [206 173 184]]\n",
      "\n",
      " [[107  73  71]\n",
      "  [112  78  76]\n",
      "  [118  83  81]\n",
      "  ...\n",
      "  [196 163 174]\n",
      "  [198 165 176]\n",
      "  [204 171 182]]\n",
      "\n",
      " [[107  73  71]\n",
      "  [109  75  73]\n",
      "  [112  77  75]\n",
      "  ...\n",
      "  [198 165 176]\n",
      "  [199 166 177]\n",
      "  [201 168 179]]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    label_map={}\n",
    "    \n",
    "    for i, class_name in enumerate(data.keys()):\n",
    "        label_map[class_name] = i\n",
    "\n",
    "        for image in data[class_name]:\n",
    "            try:\n",
    "                with Image.open(image) as img:\n",
    "                    img_array = np.array(img)\n",
    "                    x.append(img_array)\n",
    "                    y.append(label_map[class_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image}: {e}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y, label_map\n",
    "    \n",
    "\n",
    "x_train, y_train, label_map_train = prepare_data(train_data)\n",
    "x_test, y_test, label_map_test = prepare_data(test_data)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(label_map_train)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(label_map_test)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "\n",
    "print(x_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936fee7",
   "metadata": {},
   "source": [
    "### Data Augmentation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "827cc853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of minor class samples: 11724\n",
      "Number of major class samples: 12775\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.5),\n",
    "    A.GridDropout(ratio=0.3, p=0.5),\n",
    "])\n",
    "\n",
    "# Define the minor and major classes\n",
    "minor_classes = [0, 1, 2, 3, 4, 6, 7]\n",
    "minor_class_indices = np.where(np.isin(y_train, minor_classes))[0]\n",
    "major_class_indices = np.where(~np.isin(y_train, minor_classes))[0]\n",
    "\n",
    "print(f\"Number of minor class samples: {len(minor_class_indices)}\")\n",
    "print(f\"Number of major class samples: {len(major_class_indices)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "774a8346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12775\n",
      "Original size: 735, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 735/735 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 3265/3265 [00:04<00:00, 762.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 3223, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 3223/3223 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 777/777 [00:00<00:00, 1107.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 2524, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 2524/2524 [00:00<00:00, 1199051.23it/s]\n",
      "Augmenting samples: 100%|██████████| 1476/1476 [00:00<00:00, 1706.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 139, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 139/139 [00:00<00:00, 350787.16it/s]\n",
      "Augmenting samples: 100%|██████████| 3861/3861 [00:01<00:00, 2004.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 4422, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 4422/4422 [00:00<?, ?it/s]\n",
      "Augmenting samples: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 528, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 528/528 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 3472/3472 [00:01<00:00, 1822.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 153, target size: 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 153/153 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 3847/3847 [00:01<00:00, 2129.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset size: 41197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset with augmented samples\n",
    "new_x_train = [x_train[i] for i in major_class_indices]\n",
    "new_y_train = [y_train[i] for i in major_class_indices]\n",
    "\n",
    "print(len(new_x_train))\n",
    "\n",
    "target_size = 4000\n",
    "\n",
    "for class_name in minor_classes:\n",
    "    class_indices = np.where(y_train == class_name)[0]\n",
    "    original_size = len(class_indices)\n",
    "    need_to_augment = target_size - original_size\n",
    "\n",
    "    print(f\"Original size: {original_size}, target size: {target_size}\")\n",
    "\n",
    "    for i in tqdm(class_indices, desc=\"Adding original samples\"):\n",
    "        image = x_train[i]\n",
    "        label = y_train[i]\n",
    "\n",
    "        # Keep original image and generate augmented images until target size is reached\n",
    "        new_x_train.append(image)\n",
    "        new_y_train.append(label)\n",
    "\n",
    "\n",
    "    # Augment the dataset until the target size is reached\n",
    "    with tqdm(total=need_to_augment, desc=\"Augmenting samples\") as pbar:\n",
    "        while need_to_augment > 0:\n",
    "            sample = x_train[np.random.choice(class_indices)]\n",
    "            augmented = transform(image=sample)['image']\n",
    "            new_x_train.append(augmented)\n",
    "            new_y_train.append(label)\n",
    "            need_to_augment -= 1\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"New dataset size: {len(new_x_train)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba430d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "new_x_train = np.array(new_x_train)\n",
    "new_y_train = np.array(new_y_train)\n",
    "\n",
    "new_x_train = new_x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "num_classes = len(label_map_train)\n",
    "new_y_train_cat = tf.keras.utils.to_categorical(new_y_train, num_classes)\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e15d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    # First convolutional block\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=new_x_train.shape[1:], kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Second convolutional block\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Third convolutional block\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.5),\n",
    "    \n",
    "    # Flatten and fully connected layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.7),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ca053a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Define callbacks for training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3995daef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 2s/step - accuracy: 0.3531 - loss: 3.7153 - val_accuracy: 0.1575 - val_loss: 6.9902 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 2s/step - accuracy: 0.4776 - loss: 2.5363 - val_accuracy: 0.2675 - val_loss: 4.0310 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 2s/step - accuracy: 0.5164 - loss: 2.1362 - val_accuracy: 0.2188 - val_loss: 4.0569 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.5486 - loss: 2.0105 - val_accuracy: 0.2438 - val_loss: 3.9713 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 1s/step - accuracy: 0.5655 - loss: 2.0006 - val_accuracy: 0.3700 - val_loss: 2.4743 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.5956 - loss: 1.9269 - val_accuracy: 0.3262 - val_loss: 2.8329 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.6125 - loss: 1.8789 - val_accuracy: 0.3487 - val_loss: 2.8247 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.6263 - loss: 1.8974 - val_accuracy: 0.3137 - val_loss: 2.9082 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 1s/step - accuracy: 0.6415 - loss: 1.9409 - val_accuracy: 0.3225 - val_loss: 3.0351 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6456 - loss: 1.9736\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 1s/step - accuracy: 0.6456 - loss: 1.9737 - val_accuracy: 0.3950 - val_loss: 2.7991 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m475s\u001b[0m 1s/step - accuracy: 0.6842 - loss: 1.8002 - val_accuracy: 0.4913 - val_loss: 2.2025 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 1s/step - accuracy: 0.7085 - loss: 1.5560 - val_accuracy: 0.4837 - val_loss: 2.2776 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 1s/step - accuracy: 0.7187 - loss: 1.5491 - val_accuracy: 0.3650 - val_loss: 2.7944 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 1s/step - accuracy: 0.7191 - loss: 1.5723 - val_accuracy: 0.4950 - val_loss: 2.2987 - learning_rate: 5.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 1s/step - accuracy: 0.7318 - loss: 1.5622 - val_accuracy: 0.4387 - val_loss: 2.6412 - learning_rate: 5.0000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7352 - loss: 1.5630\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 1s/step - accuracy: 0.7352 - loss: 1.5631 - val_accuracy: 0.4938 - val_loss: 2.3097 - learning_rate: 5.0000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 1s/step - accuracy: 0.7560 - loss: 1.4866 - val_accuracy: 0.4512 - val_loss: 2.3994 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 1s/step - accuracy: 0.7776 - loss: 1.3116 - val_accuracy: 0.4975 - val_loss: 2.2780 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 1s/step - accuracy: 0.7892 - loss: 1.2298 - val_accuracy: 0.5125 - val_loss: 2.1733 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 1s/step - accuracy: 0.7971 - loss: 1.1918 - val_accuracy: 0.5000 - val_loss: 2.1984 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 1s/step - accuracy: 0.7938 - loss: 1.1952 - val_accuracy: 0.5200 - val_loss: 2.2080 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 1s/step - accuracy: 0.8017 - loss: 1.1769 - val_accuracy: 0.5050 - val_loss: 2.3084 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 1s/step - accuracy: 0.8061 - loss: 1.1681 - val_accuracy: 0.5450 - val_loss: 2.1225 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 1s/step - accuracy: 0.8156 - loss: 1.1412 - val_accuracy: 0.4825 - val_loss: 2.3079 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 1s/step - accuracy: 0.8196 - loss: 1.1392 - val_accuracy: 0.4812 - val_loss: 2.3557 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 1s/step - accuracy: 0.8161 - loss: 1.1509 - val_accuracy: 0.5337 - val_loss: 2.2281 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 1s/step - accuracy: 0.8229 - loss: 1.1353 - val_accuracy: 0.5213 - val_loss: 2.3453 - learning_rate: 2.5000e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8236 - loss: 1.1358\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 1s/step - accuracy: 0.8236 - loss: 1.1359 - val_accuracy: 0.5537 - val_loss: 2.1743 - learning_rate: 2.5000e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 1s/step - accuracy: 0.8381 - loss: 1.0886 - val_accuracy: 0.5288 - val_loss: 2.2218 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m322/322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 1s/step - accuracy: 0.8534 - loss: 1.0187 - val_accuracy: 0.5312 - val_loss: 2.2103 - learning_rate: 1.2500e-04\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.5277 - loss: 2.0919\n",
      "Test accuracy: 0.5450\n",
      "Test loss: 2.1225\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    new_x_train, new_y_train_cat,\n",
    "    epochs=30,\n",
    "    batch_size=128,\n",
    "    validation_data=(x_test, y_test_cat),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e6e7fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (800, 84, 84, 3)\n",
      "y_test shape: (800, 8)\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "y_pred shape: (800, 8)\n",
      "Classification Report:\n",
      "                               precision    recall  f1-score   support\n",
      "\n",
      "       Actinic Keratosis (AK)       0.12      1.00      0.22       100\n",
      "   Basal Cell Carcinoma (BCC)       0.00      0.00      0.00       100\n",
      "       Benign Keratosis (BKL)       0.00      0.00      0.00       100\n",
      "          Dermatofibroma (DF)       0.00      0.00      0.00       100\n",
      "               Melanoma (MEL)       0.00      0.00      0.00       100\n",
      "       Melanocytic Nevus (NV)       0.00      0.00      0.00       100\n",
      "Squamous Cell Carcinoma (SCC)       0.00      0.00      0.00       100\n",
      "       Vascular Lesion (VASC)       0.00      0.00      0.00       100\n",
      "\n",
      "                     accuracy                           0.12       800\n",
      "                    macro avg       0.02      0.12      0.03       800\n",
      "                 weighted avg       0.02      0.12      0.03       800\n",
      "\n",
      "ROC-AUC (One-vs-Rest): 0.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"x_test shape:\", x_test.shape)  # Expected: (800, 84, 84, 3) or similar\n",
    "print(\"y_test shape:\", y_test.shape)  # Expected: (800, 8) for one-hot, or (800,) for integer labels\n",
    "\n",
    "# Preprocess x_test (ensure normalization and correct shape)\n",
    "x_test = x_test.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "# If model expects different size (e.g., 84x84), resize if needed\n",
    "# x_test = tf.image.resize(x_test, [84, 84]).numpy()\n",
    "\n",
    "# Check if y_test is one-hot encoded; convert if integer labels\n",
    "if len(y_test.shape) == 1 or y_test.shape[1] == 1:\n",
    "    print(\"Converting y_test to one-hot encoded format\")\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=8)\n",
    "\n",
    "# Generate predictions\n",
    "try:\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(\"y_pred shape:\", y_pred.shape)  # Expected: (800, 8)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "except Exception as e:A\n",
    "    print(f\"Error in prediction: {e}\")\n",
    "    raise\n",
    "\n",
    "# Classification report\n",
    "class_names = [\n",
    "    'Actinic Keratosis (AK)',\n",
    "    'Basal Cell Carcinoma (BCC)',\n",
    "    'Benign Keratosis (BKL)',\n",
    "    'Dermatofibroma (DF)',\n",
    "    'Melanoma (MEL)',\n",
    "    'Melanocytic Nevus (NV)',\n",
    "    'Squamous Cell Carcinoma (SCC)',\n",
    "    'Vascular Lesion (VASC)'\n",
    "]\n",
    "print(\"Classification Report:\")\n",
    "try:\n",
    "    print(classification_report(y_test_classes, y_pred_classes, target_names=class_names))\n",
    "except Exception as e:\n",
    "    print(f\"Error in classification report: {e}\")\n",
    "    raise\n",
    "\n",
    "# ROC-AUC score\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "    print(f\"ROC-AUC (One-vs-Rest): {roc_auc:.4f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"ROC-AUC calculation failed: {e}\")\n",
    "\n",
    "# Confusion Matrix Heatmap (for report)\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png', dpi=300)  # Save for report\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05838f9b",
   "metadata": {},
   "source": [
    "## New Implement ##\n",
    "### Result still bad, try to improve the pre-process and use transfer learning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e722ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of minor class samples: 4079\n",
      "Number of major class samples: 20420\n"
     ]
    }
   ],
   "source": [
    "# Define the augmentation pipeline\n",
    "transform = A.Compose([\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.GaussianBlur(blur_limit=3, p=0.5),\n",
    "    A.GridDropout(ratio=0.3, p=0.5),\n",
    "])\n",
    "\n",
    "# Define the minor and major classes\n",
    "minor_classes = [0, 2, 3, 6, 7]\n",
    "minor_class_indices = np.where(np.isin(y_train, minor_classes))[0]\n",
    "major_class_indices = np.where(~np.isin(y_train, minor_classes))[0]\n",
    "\n",
    "print(f\"Number of minor class samples: {len(minor_class_indices)}\")\n",
    "print(f\"Number of major class samples: {len(major_class_indices)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "518863eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20420\n",
      "Original size: 735, target size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 735/735 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting samples: 100%|██████████| 2265/2265 [00:00<00:00, 2677.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 2524, target size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 2524/2524 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 476/476 [00:00<00:00, 2066.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 139, target size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 139/139 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 2861/2861 [00:01<00:00, 2630.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 528, target size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 528/528 [00:00<00:00, 524784.96it/s]\n",
      "Augmenting samples: 100%|██████████| 2472/2472 [00:01<00:00, 2358.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 153, target size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding original samples: 100%|██████████| 153/153 [00:00<?, ?it/s]\n",
      "Augmenting samples: 100%|██████████| 2847/2847 [00:01<00:00, 2258.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset size: 35420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataset with augmented samples\n",
    "new_x_train = [x_train[i] for i in major_class_indices]\n",
    "new_y_train = [y_train[i] for i in major_class_indices]\n",
    "\n",
    "print(len(new_x_train))\n",
    "\n",
    "target_size = 3000 #4000 maybe too many for those rare classes, dont want to have fake data\n",
    "\n",
    "for class_name in minor_classes:\n",
    "    class_indices = np.where(y_train == class_name)[0]\n",
    "    original_size = len(class_indices)\n",
    "    need_to_augment = target_size - original_size\n",
    "\n",
    "    print(f\"Original size: {original_size}, target size: {target_size}\")\n",
    "\n",
    "    for i in tqdm(class_indices, desc=\"Adding original samples\"):\n",
    "        image = x_train[i]\n",
    "        label = y_train[i]\n",
    "\n",
    "        # Keep original image and generate augmented images until target size is reached\n",
    "        new_x_train.append(image)\n",
    "        new_y_train.append(label)\n",
    "\n",
    "\n",
    "    # Augment the dataset until the target size is reached\n",
    "    with tqdm(total=need_to_augment, desc=\"Augmenting samples\") as pbar:\n",
    "        while need_to_augment > 0:\n",
    "            sample = x_train[np.random.choice(class_indices)]\n",
    "            augmented = transform(image=sample)['image']\n",
    "            new_x_train.append(augmented)\n",
    "            new_y_train.append(label)\n",
    "            need_to_augment -= 1\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "print(f\"New dataset size: {len(new_x_train)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818ea3a",
   "metadata": {},
   "source": [
    "### Pre-process for Transfer learning(EffiecntNet) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c7d2ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35420, 84, 84, 3) (35420,) (800, 84, 84, 3) (800,) uint8\n",
      "(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Pre-process(resize the image to 224x224)\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Change training data to tf.dataset\n",
    "new_x_train = np.array(new_x_train)\n",
    "new_y_train = np.array(new_y_train)\n",
    "\n",
    "print(new_x_train.shape, new_y_train.shape, x_test.shape, y_test.shape, new_x_train.dtype)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((new_x_train, new_y_train))\n",
    "train_dataset = train_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(10000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d42a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# model setup(transfer learning)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m EfficientNetB0(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m base_model\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# freeze\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      6\u001b[0m     base_model,\n\u001b[0;32m      7\u001b[0m     GlobalAveragePooling2D(),\n\u001b[0;32m      8\u001b[0m     Dropout(\u001b[38;5;241m0.3\u001b[39m),\n\u001b[0;32m      9\u001b[0m     Dense(\u001b[38;5;241m8\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:568\u001b[0m, in \u001b[0;36mEfficientNetB0\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[0;32m    553\u001b[0m     [\n\u001b[0;32m    554\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    567\u001b[0m ):\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EfficientNet(\n\u001b[0;32m    569\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    570\u001b[0m         \u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m    571\u001b[0m         \u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m    572\u001b[0m         \u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m    573\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnetb0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    574\u001b[0m         include_top\u001b[38;5;241m=\u001b[39minclude_top,\n\u001b[0;32m    575\u001b[0m         weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m    576\u001b[0m         input_tensor\u001b[38;5;241m=\u001b[39minput_tensor,\n\u001b[0;32m    577\u001b[0m         input_shape\u001b[38;5;241m=\u001b[39minput_shape,\n\u001b[0;32m    578\u001b[0m         pooling\u001b[38;5;241m=\u001b[39mpooling,\n\u001b[0;32m    579\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    580\u001b[0m         classifier_activation\u001b[38;5;241m=\u001b[39mclassifier_activation,\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    582\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:297\u001b[0m, in \u001b[0;36mEfficientNet\u001b[1;34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    287\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m imagenet_utils\u001b[38;5;241m.\u001b[39mobtain_input_shape(\n\u001b[0;32m    288\u001b[0m     input_shape,\n\u001b[0;32m    289\u001b[0m     default_size\u001b[38;5;241m=\u001b[39mdefault_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    293\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[0;32m    294\u001b[0m )\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     img_input \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39minput_shape)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_keras_tensor(input_tensor):\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:143\u001b[0m, in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, dtype, sparse, batch_shape, name, tensor)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.layers.Input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.Input\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInput\u001b[39m(\n\u001b[0;32m     91\u001b[0m     shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m     tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     98\u001b[0m ):\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Used to instantiate a Keras tensor.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    A Keras tensor is a symbolic tensor-like object, which we augment with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 143\u001b[0m     layer \u001b[38;5;241m=\u001b[39m InputLayer(\n\u001b[0;32m    144\u001b[0m         shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m    145\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    146\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    147\u001b[0m         sparse\u001b[38;5;241m=\u001b[39msparse,\n\u001b[0;32m    148\u001b[0m         batch_shape\u001b[38;5;241m=\u001b[39mbatch_shape,\n\u001b[0;32m    149\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m    150\u001b[0m         input_tensor\u001b[38;5;241m=\u001b[39mtensor,\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:216\u001b[0m, in \u001b[0;36mLayer.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# Wrap the user-provided build method in the build_decorator\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# to add name scope support and serialization support.\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m     original_build_method \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mbuild\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;129m@wraps\u001b[39m(original_build_method)\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model setup(transfer learning)\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # freeze\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.3),\n",
    "    Dense(8, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# define callback for training\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e328d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 414ms/step - accuracy: 0.6998 - loss: 0.7461 - val_accuracy: 0.3837 - val_loss: 1.6167 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 410ms/step - accuracy: 0.7058 - loss: 0.7501 - val_accuracy: 0.3725 - val_loss: 1.6285 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 422ms/step - accuracy: 0.7196 - loss: 0.7216 - val_accuracy: 0.4412 - val_loss: 1.4939 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 422ms/step - accuracy: 0.7220 - loss: 0.7114 - val_accuracy: 0.4538 - val_loss: 1.4797 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 389ms/step - accuracy: 0.7221 - loss: 0.7156 - val_accuracy: 0.4162 - val_loss: 1.5545 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 396ms/step - accuracy: 0.7203 - loss: 0.7110 - val_accuracy: 0.4487 - val_loss: 1.4800 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 394ms/step - accuracy: 0.7231 - loss: 0.7126 - val_accuracy: 0.4575 - val_loss: 1.4415 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 405ms/step - accuracy: 0.7330 - loss: 0.6852 - val_accuracy: 0.4125 - val_loss: 1.5568 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 418ms/step - accuracy: 0.7301 - loss: 0.6987 - val_accuracy: 0.4600 - val_loss: 1.4375 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 430ms/step - accuracy: 0.7212 - loss: 0.7071 - val_accuracy: 0.4475 - val_loss: 1.4673 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 408ms/step - accuracy: 0.7331 - loss: 0.6888 - val_accuracy: 0.4338 - val_loss: 1.4813 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 402ms/step - accuracy: 0.7321 - loss: 0.6925 - val_accuracy: 0.4775 - val_loss: 1.4535 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 417ms/step - accuracy: 0.7267 - loss: 0.6971 - val_accuracy: 0.4712 - val_loss: 1.4272 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 405ms/step - accuracy: 0.7333 - loss: 0.6915 - val_accuracy: 0.4200 - val_loss: 1.5438 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 404ms/step - accuracy: 0.7271 - loss: 0.7010 - val_accuracy: 0.4525 - val_loss: 1.5015 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 399ms/step - accuracy: 0.7244 - loss: 0.7035 - val_accuracy: 0.4450 - val_loss: 1.4643 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 385ms/step - accuracy: 0.7304 - loss: 0.6939 - val_accuracy: 0.4600 - val_loss: 1.4978 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 394ms/step - accuracy: 0.7244 - loss: 0.7020 - val_accuracy: 0.4600 - val_loss: 1.4194 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 408ms/step - accuracy: 0.7285 - loss: 0.6931 - val_accuracy: 0.4437 - val_loss: 1.4656 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 405ms/step - accuracy: 0.7301 - loss: 0.6969 - val_accuracy: 0.4650 - val_loss: 1.4418 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 396ms/step - accuracy: 0.7348 - loss: 0.6803 - val_accuracy: 0.4500 - val_loss: 1.4612 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 398ms/step - accuracy: 0.7307 - loss: 0.6919 - val_accuracy: 0.4225 - val_loss: 1.5527 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 399ms/step - accuracy: 0.7282 - loss: 0.6931 - val_accuracy: 0.4588 - val_loss: 1.4305 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 401ms/step - accuracy: 0.7178 - loss: 0.7307 - val_accuracy: 0.4363 - val_loss: 1.4717 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 399ms/step - accuracy: 0.7244 - loss: 0.7118 - val_accuracy: 0.4500 - val_loss: 1.4720 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 413ms/step - accuracy: 0.7224 - loss: 0.7220 - val_accuracy: 0.4725 - val_loss: 1.4246 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 402ms/step - accuracy: 0.7261 - loss: 0.7129 - val_accuracy: 0.4750 - val_loss: 1.4300 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 409ms/step - accuracy: 0.7178 - loss: 0.7151 - val_accuracy: 0.4650 - val_loss: 1.4260 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history_1 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db5db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val accuracy: 0.47749999165534973\n"
     ]
    }
   ],
   "source": [
    "print(\"Best val accuracy:\", max(history_1.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717709a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2968s\u001b[0m 3s/step - accuracy: 0.4804 - loss: 1.3760 - val_accuracy: 0.3700 - val_loss: 1.7635 - learning_rate: 1.0000e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2305s\u001b[0m 2s/step - accuracy: 0.4445 - loss: 1.4257 - val_accuracy: 0.4025 - val_loss: 1.5744 - learning_rate: 1.0000e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2347s\u001b[0m 2s/step - accuracy: 0.5073 - loss: 1.2216 - val_accuracy: 0.4712 - val_loss: 1.4421 - learning_rate: 1.0000e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2228s\u001b[0m 2s/step - accuracy: 0.5527 - loss: 1.0730 - val_accuracy: 0.4925 - val_loss: 1.3713 - learning_rate: 1.0000e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2223s\u001b[0m 2s/step - accuracy: 0.5956 - loss: 0.9681 - val_accuracy: 0.5063 - val_loss: 1.3076 - learning_rate: 1.0000e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2240s\u001b[0m 2s/step - accuracy: 0.6220 - loss: 0.8776 - val_accuracy: 0.5113 - val_loss: 1.2788 - learning_rate: 1.0000e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2219s\u001b[0m 2s/step - accuracy: 0.6450 - loss: 0.8303 - val_accuracy: 0.5312 - val_loss: 1.2438 - learning_rate: 1.0000e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2266s\u001b[0m 2s/step - accuracy: 0.6657 - loss: 0.7741 - val_accuracy: 0.5350 - val_loss: 1.2364 - learning_rate: 1.0000e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2309s\u001b[0m 2s/step - accuracy: 0.6761 - loss: 0.7340 - val_accuracy: 0.5575 - val_loss: 1.1937 - learning_rate: 1.0000e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2314s\u001b[0m 2s/step - accuracy: 0.6962 - loss: 0.6809 - val_accuracy: 0.5638 - val_loss: 1.1970 - learning_rate: 1.0000e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2255s\u001b[0m 2s/step - accuracy: 0.7053 - loss: 0.6620 - val_accuracy: 0.5738 - val_loss: 1.1517 - learning_rate: 1.0000e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2228s\u001b[0m 2s/step - accuracy: 0.7164 - loss: 0.6329 - val_accuracy: 0.5850 - val_loss: 1.1354 - learning_rate: 1.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2311s\u001b[0m 2s/step - accuracy: 0.7191 - loss: 0.6181 - val_accuracy: 0.5863 - val_loss: 1.1348 - learning_rate: 1.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2497s\u001b[0m 2s/step - accuracy: 0.7349 - loss: 0.5833 - val_accuracy: 0.5925 - val_loss: 1.1332 - learning_rate: 1.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2580s\u001b[0m 2s/step - accuracy: 0.7440 - loss: 0.5541 - val_accuracy: 0.5950 - val_loss: 1.1190 - learning_rate: 1.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2744s\u001b[0m 2s/step - accuracy: 0.7544 - loss: 0.5343 - val_accuracy: 0.6075 - val_loss: 1.1240 - learning_rate: 1.0000e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2715s\u001b[0m 2s/step - accuracy: 0.7553 - loss: 0.5193 - val_accuracy: 0.6112 - val_loss: 1.1121 - learning_rate: 1.0000e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2688s\u001b[0m 2s/step - accuracy: 0.7613 - loss: 0.5036 - val_accuracy: 0.6125 - val_loss: 1.1078 - learning_rate: 1.0000e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2702s\u001b[0m 2s/step - accuracy: 0.7711 - loss: 0.4887 - val_accuracy: 0.6037 - val_loss: 1.1302 - learning_rate: 1.0000e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2672s\u001b[0m 2s/step - accuracy: 0.7791 - loss: 0.4671 - val_accuracy: 0.6125 - val_loss: 1.1098 - learning_rate: 1.0000e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m1107/1107\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2652s\u001b[0m 2s/step - accuracy: 0.7885 - loss: 0.4507 - val_accuracy: 0.6112 - val_loss: 1.1164 - learning_rate: 1.0000e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m 100/1107\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42:41\u001b[0m 3s/step - accuracy: 0.7548 - loss: 0.5746"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block5a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block5a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter}}]] [Op:__inference_one_step_on_iterator_649719]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m),\n\u001b[0;32m     10\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     15\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     16\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m)\n\u001b[0;32m     17\u001b[0m ]\n\u001b[1;32m---> 19\u001b[0m history_fine_tune \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     20\u001b[0m     train_dataset,\n\u001b[0;32m     21\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m     22\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,           \n\u001b[0;32m     23\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     24\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     25\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block5a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block5a_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter}}]] [Op:__inference_one_step_on_iterator_649719]"
     ]
    }
   ],
   "source": [
    "# Fine-tune\n",
    "base_model.trainable = True \n",
    "\n",
    "# Adjust class-weight\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(new_y_train), y=new_y_train)\n",
    "class_weight_dict = dict(zip(np.unique(new_y_train), class_weights))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "history_fine_tune = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c0a3c3",
   "metadata": {},
   "source": [
    "## Not enough ram and memory (Reduce unfreeze layers to 80 and batch size to 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5209af11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save(\"skin_cancer_classification_model_21epoch.keras\")\n",
    "print(\"Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ef5170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only train 80 layers\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-80]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-80:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "print(f\"Only train {sum(l.trainable for l in base_model.layers)} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61841e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "   2214/Unknown \u001b[1m1396s\u001b[0m 610ms/step - accuracy: 0.7858 - loss: 0.4354"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mande\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23: val_accuracy improved from -inf to 0.59750, saving model to best_skin_model.keras\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1415s\u001b[0m 618ms/step - accuracy: 0.7858 - loss: 0.4354 - val_accuracy: 0.5975 - val_loss: 1.1231 - learning_rate: 1.0000e-05\n",
      "Epoch 24/100\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.7638 - loss: 0.5045\n",
      "Epoch 24: val_accuracy improved from 0.59750 to 0.61625, saving model to best_skin_model.keras\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1388s\u001b[0m 625ms/step - accuracy: 0.7638 - loss: 0.5045 - val_accuracy: 0.6162 - val_loss: 1.0972 - learning_rate: 1.0000e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755ms/step - accuracy: 0.7766 - loss: 0.4677\n",
      "Epoch 25: val_accuracy did not improve from 0.61625\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1702s\u001b[0m 765ms/step - accuracy: 0.7766 - loss: 0.4677 - val_accuracy: 0.6137 - val_loss: 1.1152 - learning_rate: 1.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - accuracy: 0.7845 - loss: 0.4611\n",
      "Epoch 26: val_accuracy did not improve from 0.61625\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 682ms/step - accuracy: 0.7845 - loss: 0.4611 - val_accuracy: 0.6100 - val_loss: 1.1397 - learning_rate: 1.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698ms/step - accuracy: 0.7844 - loss: 0.4522\n",
      "Epoch 27: val_accuracy did not improve from 0.61625\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1577s\u001b[0m 708ms/step - accuracy: 0.7844 - loss: 0.4522 - val_accuracy: 0.6125 - val_loss: 1.1343 - learning_rate: 1.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - accuracy: 0.7835 - loss: 0.4424\n",
      "Epoch 28: val_accuracy did not improve from 0.61625\n",
      "\u001b[1m2214/2214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1541s\u001b[0m 695ms/step - accuracy: 0.7835 - loss: 0.4424 - val_accuracy: 0.6162 - val_loss: 1.1391 - learning_rate: 1.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m 569/2214\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:25\u001b[0m 672ms/step - accuracy: 0.7852 - loss: 0.4729"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block6d_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block6d_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter}}]] [Op:__inference_one_step_on_iterator_1018107]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 22\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m), \n\u001b[0;32m      7\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m ]\n\u001b[1;32m---> 22\u001b[0m history_fine_tune_1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     23\u001b[0m     train_dataset,\n\u001b[0;32m     24\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m     25\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     26\u001b[0m     initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m22\u001b[39m,           \n\u001b[0;32m     27\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     28\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block6d_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_grad_filter_ops.cc:685\n\t [[{{node StatefulPartitionedCall/gradient_tape/sequential_3_1/efficientnetb0_1/block6d_dwconv_1/depthwise/DepthwiseConv2dNativeBackpropFilter}}]] [Op:__inference_one_step_on_iterator_1018107]"
     ]
    }
   ],
   "source": [
    "# Continue the training\n",
    "train_dataset = train_dataset.unbatch().batch(16) # Reduce the batch size\n",
    "val_dataset   = val_dataset.unbatch().batch(16)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5), \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1, min_lr=1e-7),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_skin_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine_tune_1 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    initial_epoch = 22,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8d9f4",
   "metadata": {},
   "source": [
    "### Again! Reduce batch size to 8 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ea4e236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "   4428/Unknown \u001b[1m1291s\u001b[0m 280ms/step - accuracy: 0.8079 - loss: 0.3956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mande\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30: val_accuracy improved from -inf to 0.61875, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 286ms/step - accuracy: 0.8079 - loss: 0.3957 - val_accuracy: 0.6187 - val_loss: 1.1326 - learning_rate: 1.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7868 - loss: 0.4441\n",
      "Epoch 31: val_accuracy improved from 0.61875 to 0.62500, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1404s\u001b[0m 317ms/step - accuracy: 0.7868 - loss: 0.4441 - val_accuracy: 0.6250 - val_loss: 1.1664 - learning_rate: 1.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7923 - loss: 0.4251\n",
      "Epoch 32: val_accuracy improved from 0.62500 to 0.63750, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1406s\u001b[0m 317ms/step - accuracy: 0.7923 - loss: 0.4251 - val_accuracy: 0.6375 - val_loss: 1.1734 - learning_rate: 1.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.7981 - loss: 0.4166\n",
      "Epoch 33: val_accuracy did not improve from 0.63750\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1424s\u001b[0m 321ms/step - accuracy: 0.7981 - loss: 0.4167 - val_accuracy: 0.6350 - val_loss: 1.1821 - learning_rate: 1.0000e-05\n",
      "Epoch 34/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8113 - loss: 0.3874\n",
      "Epoch 34: val_accuracy did not improve from 0.63750\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1412s\u001b[0m 318ms/step - accuracy: 0.8113 - loss: 0.3874 - val_accuracy: 0.6313 - val_loss: 1.1599 - learning_rate: 1.0000e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.8121 - loss: 0.3874"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\mande\\AppData\\Local\\Temp\\ipykernel_14668\\2034194149.py\", line 22, in <module>\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 339, in fit\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 78, in test_step\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 209, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 243, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 233, in convolution_op\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 909, in conv\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 255, in conv\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 231, in _conv\n\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution}}]] [Op:__inference_one_step_on_iterator_1313898]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 22\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-5\u001b[39m), \n\u001b[0;32m      7\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m ]\n\u001b[1;32m---> 22\u001b[0m history_fine_tune_2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     23\u001b[0m     train_dataset,\n\u001b[0;32m     24\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m     25\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     26\u001b[0m     initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m29\u001b[39m,           \n\u001b[0;32m     27\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     28\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     29\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\mande\\AppData\\Local\\Temp\\ipykernel_14668\\2034194149.py\", line 22, in <module>\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 339, in fit\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 425, in evaluate\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 161, in one_step_on_iterator\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 150, in one_step_on_data\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py\", line 78, in test_step\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\sequential.py\", line 209, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 202, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py\", line 155, in _run_through_graph\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py\", line 592, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py\", line 846, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 117, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py\", line 48, in __call__\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 156, in error_handler\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 243, in call\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py\", line 233, in convolution_op\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\ops\\nn.py\", line 909, in conv\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 255, in conv\n\n  File \"c:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 231, in _conv\n\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution}}]] [Op:__inference_one_step_on_iterator_1313898]"
     ]
    }
   ],
   "source": [
    "# Continue the training\n",
    "train_dataset = train_dataset.unbatch().batch(8) # Reduce the batch size\n",
    "val_dataset   = val_dataset.unbatch().batch(8)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5), \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1, min_lr=1e-7),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_skin_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine_tune_2 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    initial_epoch = 29,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80832982",
   "metadata": {},
   "source": [
    "### Reduce unfreeze layers to 50, batch size = 8 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4315a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "   4428/Unknown \u001b[1m1131s\u001b[0m 247ms/step - accuracy: 0.7940 - loss: 0.4288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mande\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36: val_accuracy improved from -inf to 0.62250, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 252ms/step - accuracy: 0.7940 - loss: 0.4288 - val_accuracy: 0.6225 - val_loss: 1.2123 - learning_rate: 5.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m1292/4428\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:15\u001b[0m 254ms/step - accuracy: 0.7853 - loss: 0.4626"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 29\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m5e-6\u001b[39m), \u001b[38;5;66;03m# Reduce learning rate\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     20\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m ]\n\u001b[1;32m---> 29\u001b[0m history_fine_tune_3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     30\u001b[0m     train_dataset,\n\u001b[0;32m     31\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m     32\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     33\u001b[0m     initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m,           \n\u001b[0;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     35\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue the training\n",
    "train_dataset = train_dataset.unbatch().batch(8) \n",
    "val_dataset   = val_dataset.unbatch().batch(8)\n",
    "\n",
    "# Only unfreeze last 50 layers\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-50]:   \n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-6), # Reduce learning rate\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=25, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1, min_lr=1e-7),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_skin_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine_tune_3 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    initial_epoch = 35,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90338016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.8412 - loss: 0.3228\n",
      "Epoch 38: val_accuracy improved from -inf to 0.63000, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1301s\u001b[0m 286ms/step - accuracy: 0.8412 - loss: 0.3228 - val_accuracy: 0.6300 - val_loss: 1.1984 - learning_rate: 5.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.8119 - loss: 0.3838\n",
      "Epoch 39: val_accuracy did not improve from 0.63000\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1214s\u001b[0m 274ms/step - accuracy: 0.8119 - loss: 0.3838 - val_accuracy: 0.6250 - val_loss: 1.2363 - learning_rate: 5.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.8206 - loss: 0.3643\n",
      "Epoch 40: val_accuracy improved from 0.63000 to 0.63250, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1203s\u001b[0m 272ms/step - accuracy: 0.8206 - loss: 0.3643 - val_accuracy: 0.6325 - val_loss: 1.2181 - learning_rate: 5.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.8229 - loss: 0.3601\n",
      "Epoch 41: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1228s\u001b[0m 277ms/step - accuracy: 0.8229 - loss: 0.3601 - val_accuracy: 0.6212 - val_loss: 1.2551 - learning_rate: 5.0000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.8262 - loss: 0.3564\n",
      "Epoch 42: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1239s\u001b[0m 280ms/step - accuracy: 0.8262 - loss: 0.3564 - val_accuracy: 0.6225 - val_loss: 1.2458 - learning_rate: 5.0000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.8295 - loss: 0.3537\n",
      "Epoch 43: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1228s\u001b[0m 277ms/step - accuracy: 0.8295 - loss: 0.3537 - val_accuracy: 0.6250 - val_loss: 1.2641 - learning_rate: 5.0000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.8318 - loss: 0.3349\n",
      "Epoch 44: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1234s\u001b[0m 279ms/step - accuracy: 0.8318 - loss: 0.3349 - val_accuracy: 0.6263 - val_loss: 1.2834 - learning_rate: 5.0000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.8374 - loss: 0.3370\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1242s\u001b[0m 280ms/step - accuracy: 0.8374 - loss: 0.3370 - val_accuracy: 0.6250 - val_loss: 1.2577 - learning_rate: 5.0000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8249 - loss: 0.3663\n",
      "Epoch 46: val_accuracy did not improve from 0.63250\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1252s\u001b[0m 283ms/step - accuracy: 0.8249 - loss: 0.3663 - val_accuracy: 0.6237 - val_loss: 1.2826 - learning_rate: 2.5000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m2333/4428\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11:27\u001b[0m 328ms/step - accuracy: 0.8149 - loss: 0.3562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 22\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m5e-6\u001b[39m), \u001b[38;5;66;03m# Reduce learning rate\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     13\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m ]\n\u001b[1;32m---> 22\u001b[0m history_fine_tune_4 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     23\u001b[0m     train_dataset,\n\u001b[0;32m     24\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[0;32m     25\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     26\u001b[0m     initial_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m37\u001b[39m,\n\u001b[0;32m     27\u001b[0m     steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4428\u001b[39m,\n\u001b[0;32m     28\u001b[0m     validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,           \n\u001b[0;32m     29\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     30\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1506\u001b[0m   )\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue the training\n",
    "train_dataset = train_dataset.unbatch().batch(8).repeat() \n",
    "val_dataset   = val_dataset.unbatch().batch(8).repeat()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-6), \n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=25, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1, min_lr=1e-7),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_skin_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine_tune_4 = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=100,\n",
    "    initial_epoch = 37,\n",
    "    steps_per_epoch = 4428,\n",
    "    validation_steps = 100,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e05e51",
   "metadata": {},
   "source": [
    "### To avoid overfit, reduce unfreeze layers to 30, add real-time data augmentation and re-train the model from the best history ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0787c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust to avoid overfit\n",
    "model = tf.keras.models.load_model(\"best_skin_model.keras\")\n",
    "\n",
    "# Unfreeze last 30 layers  \n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Define real-time data augment\n",
    "def real_time_augment(image, label):\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, 0.2)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_saturation(image, 0.8, 1.2)\n",
    "    image = tf.image.random_hue(image, 0.1)\n",
    "    image = tf.image.random_crop(image, [200, 200, 3])\n",
    "\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "# Re-build data set\n",
    "def train_generator(): # Use generator to save ram\n",
    "    for i in range(len(new_x_train)):\n",
    "        yield new_x_train[i], new_y_train[i]\n",
    "\n",
    "def val_generator():\n",
    "    for i in range(len(x_test)):\n",
    "        yield x_test[i], y_test[i]\n",
    "\n",
    "\n",
    "#build dataset\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(84, 84, 3), dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)  \n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(84, 84, 3), dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(real_time_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(10000).batch(8).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(real_time_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(8).repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fbc326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.4855 - loss: 1.4575\n",
      "Epoch 1: val_accuracy improved from -inf to 0.40875, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1448s\u001b[0m 316ms/step - accuracy: 0.4855 - loss: 1.4575 - val_accuracy: 0.4087 - val_loss: 2.1065 - learning_rate: 1.0000e-06\n",
      "Epoch 2/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.4870 - loss: 1.3535\n",
      "Epoch 2: val_accuracy improved from 0.40875 to 0.44875, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1120s\u001b[0m 253ms/step - accuracy: 0.4870 - loss: 1.3536 - val_accuracy: 0.4487 - val_loss: 1.8280 - learning_rate: 1.0000e-06\n",
      "Epoch 3/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.5066 - loss: 1.2812\n",
      "Epoch 3: val_accuracy improved from 0.44875 to 0.45000, saving model to best_skin_model.keras\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1230s\u001b[0m 278ms/step - accuracy: 0.5066 - loss: 1.2812 - val_accuracy: 0.4500 - val_loss: 1.7230 - learning_rate: 1.0000e-06\n",
      "Epoch 4/100\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.5228 - loss: 1.2146\n",
      "Epoch 4: val_accuracy did not improve from 0.45000\n",
      "\u001b[1m4428/4428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1179s\u001b[0m 266ms/step - accuracy: 0.5228 - loss: 1.2147 - val_accuracy: 0.4462 - val_loss: 1.7483 - learning_rate: 1.0000e-06\n",
      "Epoch 5/100\n",
      "\u001b[1m1262/4428\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:32\u001b[0m 276ms/step - accuracy: 0.5053 - loss: 1.1942"
     ]
    },
    {
     "ename": "AbortedError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall/sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node StatefulPartitionedCall/sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution}}]] [Op:__inference_one_step_on_iterator_2380916]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAbortedError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 20\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m1e-6\u001b[39m),\n\u001b[0;32m      5\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     11\u001b[0m     ReduceLROnPlateau(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m ]\n\u001b[1;32m---> 20\u001b[0m history_fine_tune_5 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     21\u001b[0m     train_ds,\n\u001b[0;32m     22\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_ds,\n\u001b[0;32m     23\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     24\u001b[0m     steps_per_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4428\u001b[39m,\n\u001b[0;32m     25\u001b[0m     validation_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,           \n\u001b[0;32m     26\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \n\u001b[0;32m     27\u001b[0m     class_weight \u001b[38;5;241m=\u001b[39m class_weight_dict      \n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\mande\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAbortedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall/sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution defined at (most recent call last):\n<stack traces unavailable>\nOperation received an exception:Status: 1, message: could not create a memory object, in file tensorflow/core/kernels/mkl/mkl_conv_ops.cc:1112\n\t [[{{node StatefulPartitionedCall/sequential_3_1/efficientnetb0_1/block7a_project_conv_1/convolution}}]] [Op:__inference_one_step_on_iterator_2380916]"
     ]
    }
   ],
   "source": [
    "# Contiune the training\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(patience=7, factor=0.5, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_skin_model.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine_tune_5 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100,\n",
    "    steps_per_epoch = 4428,\n",
    "    validation_steps = 100,           \n",
    "    callbacks=callbacks, \n",
    "    class_weight = class_weight_dict      \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
